{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 755M (CNMeM is enabled with initial size: 80.0% of memory, CuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")   \n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    y = T.maximum(0.0, x)\n",
    "    return(y)\n",
    "def Sigmoid(x):\n",
    "    y = T.nnet.sigmoid(x)\n",
    "    return(y)\n",
    "def Tanh(x):\n",
    "    y = T.tanh(x)\n",
    "    return(y)\n",
    "def Iden(x):\n",
    "    y = x\n",
    "    return(y)\n",
    "       \n",
    "def train_conv_net(datasets, U, img_w=300, filter_hs=[3,4,5], hidden_units=[100,2],  dropout_rate=[0.5], shuffle_batch=True,\n",
    "                   n_epochs=25, batch_size=50, lr_decay = 0.95, conv_non_linear=\"relu\", activations=[Iden], sqr_norm_lim=9,\n",
    "                   non_static=True):\n",
    "    \"\"\"\n",
    "    Train a simple conv net\n",
    "    img_h = sentence length (padded where necessary)\n",
    "    img_w = word vector length (300 for word2vec)\n",
    "    filter_hs = filter window sizes    \n",
    "    hidden_units = [x,y] x is the number of feature maps (per filter window), and y is the penultimate layer\n",
    "    sqr_norm_lim = s^2 in the paper\n",
    "    lr_decay = adadelta decay parameter\n",
    "    \"\"\"    \n",
    "    rng = np.random.RandomState(3435)\n",
    "    img_h = len(datasets[0][0])-1  \n",
    "    filter_w = img_w    \n",
    "    feature_maps = hidden_units[0]\n",
    "    filter_shapes = []\n",
    "    pool_sizes = []\n",
    "    for filter_h in filter_hs:\n",
    "        filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "        pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n",
    "    parameters = [(\"image shape\",img_h,img_w),(\"filter shape\",filter_shapes), (\"hidden_units\",hidden_units),\n",
    "                  (\"dropout\", dropout_rate), (\"batch_size\",batch_size),(\"non_static\", non_static),\n",
    "                    (\"learn_decay\",lr_decay), (\"conv_non_linear\", conv_non_linear), (\"non_static\", non_static)\n",
    "                    ,(\"sqr_norm_lim\",sqr_norm_lim),(\"shuffle_batch\",shuffle_batch)]\n",
    "    print parameters    \n",
    "    \n",
    "    #define model architecture\n",
    "    index = T.lscalar()\n",
    "    x = T.matrix('x')   \n",
    "    y = T.ivector('y')\n",
    "    Words = theano.shared(value = U, name = \"Words\")\n",
    "    zero_vec_tensor = T.vector()\n",
    "    zero_vec = np.zeros(img_w)\n",
    "    set_zero = theano.function([zero_vec_tensor], updates=[(Words, T.set_subtensor(Words[0,:], \n",
    "                                zero_vec_tensor))], allow_input_downcast=True)\n",
    "    layer0_input = Words[T.cast(x.flatten(),dtype=\"int32\")].reshape((x.shape[0],1,x.shape[1],\n",
    "                                                                     Words.shape[1]))                                  \n",
    "    conv_layers = []\n",
    "    layer1_inputs = []\n",
    "    for i in xrange(len(filter_hs)):\n",
    "        filter_shape = filter_shapes[i]\n",
    "        pool_size = pool_sizes[i]\n",
    "        conv_layer = LeNetConvPoolLayer(rng, input=layer0_input,image_shape=(batch_size, 1, img_h, img_w),\n",
    "                                filter_shape=filter_shape, poolsize=pool_size, non_linear=conv_non_linear)\n",
    "        layer1_input = conv_layer.output.flatten(2)\n",
    "        conv_layers.append(conv_layer)\n",
    "        layer1_inputs.append(layer1_input)\n",
    "    layer1_input = T.concatenate(layer1_inputs,1)\n",
    "    hidden_units[0] = feature_maps*len(filter_hs)    \n",
    "    classifier = MLPDropout(rng, input=layer1_input, layer_sizes=hidden_units, activations=activations, \n",
    "                            dropout_rates=dropout_rate)\n",
    "    \n",
    "    #define parameters of the model and update functions using adadelta\n",
    "    params = classifier.params     \n",
    "    for conv_layer in conv_layers:\n",
    "        params += conv_layer.params\n",
    "    if non_static:\n",
    "        #if word vectors are allowed to change, add them as model parameters\n",
    "        params += [Words]\n",
    "    cost = classifier.negative_log_likelihood(y) \n",
    "    dropout_cost = classifier.dropout_negative_log_likelihood(y)           \n",
    "    grad_updates = sgd_updates_adadelta(params, dropout_cost, lr_decay, 1e-6, sqr_norm_lim)\n",
    "    \n",
    "    #shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate \n",
    "    #extra data (at random)\n",
    "    np.random.seed(3435)\n",
    "    if datasets[0].shape[0] % batch_size > 0:\n",
    "        extra_data_num = batch_size - datasets[0].shape[0] % batch_size\n",
    "        train_set = np.random.permutation(datasets[0])   \n",
    "        extra_data = train_set[:extra_data_num]\n",
    "        new_data=np.append(datasets[0],extra_data,axis=0)\n",
    "    else:\n",
    "        new_data = datasets[0]\n",
    "    new_data = np.random.permutation(new_data)\n",
    "    \n",
    "    #n_batches = new_data.shape[0]/batch_size\n",
    "    #n_train_batches = int(np.round(n_batches*0.9))\n",
    "    \n",
    "    n_batches = new_data.shape[0]/batch_size\n",
    "    n_train_batches = n_batches\n",
    "   \n",
    "    train_set = new_data[:,:]\n",
    "    val_set = datasets[1]\n",
    "    test_set_x = datasets[2]\n",
    "\n",
    "    \n",
    "    train_set_x, train_set_y = shared_dataset((train_set[:,:img_h],train_set[:,-1]))\n",
    "    val_set_x, val_set_y = shared_dataset((val_set[:,:img_h],val_set[:,-1]))\n",
    "    #n_val_batches = n_batches - n_train_batches\n",
    "    n_val_batches = int(np.round(val_set.shape[0]/batch_size))\n",
    "    \n",
    "    get_acc_val_model = theano.function([index], classifier.errors(y),\n",
    "        givens={\n",
    "            x: val_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "                y: val_set_y[index * batch_size: (index + 1) * batch_size]},\n",
    "                                allow_input_downcast=True)\n",
    "            \n",
    "    #compile theano functions to get train/val/test errors\n",
    "    get_acc_train_model = theano.function([index], classifier.errors(y),\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "                y: train_set_y[index * batch_size: (index + 1) * batch_size]},\n",
    "                                allow_input_downcast=True)               \n",
    "    train_model = theano.function([index], cost, updates=grad_updates,\n",
    "        givens={\n",
    "            x: train_set_x[index*batch_size:(index+1)*batch_size],\n",
    "                y: train_set_y[index*batch_size:(index+1)*batch_size]},\n",
    "                                allow_input_downcast = True)     \n",
    "    test_pred_layers_a = []\n",
    "    test_pred_layers_b = []\n",
    "    \n",
    "    \n",
    "    # If test set is large loading the whole test set can give GPU memory allocation error\n",
    "    # So we make prediction only by taking a maximum of 2000 test examples at a time\n",
    "    test_size = test_set_x.shape[0]\n",
    "    test_batch_size = 2000\n",
    "    test_iter = int(test_size/test_batch_size)\n",
    "    extra_test_size = test_size - test_iter * test_batch_size\n",
    "    \n",
    "    test_layer0_input_a = Words[T.cast(x.flatten(),dtype=\"int32\")].reshape((test_batch_size,1,img_h,Words.shape[1]))\n",
    "    for conv_layer in conv_layers:\n",
    "        test_layer0_output_a = conv_layer.predict(test_layer0_input_a, test_batch_size)\n",
    "        test_pred_layers_a.append(test_layer0_output_a.flatten(2))\n",
    "    test_layer1_input_a = T.concatenate(test_pred_layers_a, 1)\n",
    "    test_y_pred_a = classifier.predict(test_layer1_input_a)\n",
    "    \n",
    "    \n",
    "    test_layer0_input_b = Words[T.cast(x.flatten(),dtype=\"int32\")].reshape((extra_test_size,1,img_h,Words.shape[1]))\n",
    "    for conv_layer in conv_layers:\n",
    "        test_layer0_output_b = conv_layer.predict(test_layer0_input_b, extra_test_size)\n",
    "        test_pred_layers_b.append(test_layer0_output_b.flatten(2))\n",
    "    test_layer1_input_b = T.concatenate(test_pred_layers_b, 1)\n",
    "    test_y_pred_b = classifier.predict(test_layer1_input_b)\n",
    "    \n",
    "    \n",
    "    test_model_all_a = theano.function([x], test_y_pred_a, allow_input_downcast = True)   \n",
    "    test_model_all_b = theano.function([x], test_y_pred_b, allow_input_downcast = True) \n",
    "    \n",
    "    #start training over mini-batches\n",
    "    print '... training'\n",
    "    epoch = 0\n",
    "    best_val_perf = 0\n",
    "    val_perf = 0\n",
    "    test_perf = 0       \n",
    "    cost_epoch = 0  \n",
    "    while (epoch < n_epochs):\n",
    "        start_time = time.time()\n",
    "        epoch = epoch + 1\n",
    "        if shuffle_batch:\n",
    "            for minibatch_index in np.random.permutation(range(n_train_batches)):\n",
    "                cost_epoch = train_model(minibatch_index)\n",
    "                set_zero(zero_vec)\n",
    "        else:\n",
    "            for minibatch_index in xrange(n_train_batches):\n",
    "                cost_epoch = train_model(minibatch_index)  \n",
    "                set_zero(zero_vec)\n",
    "        train_losses = [get_acc_train_model(i) for i in xrange(n_train_batches)]\n",
    "        train_perf = 1 - np.mean(train_losses)\n",
    "        val_losses = [get_acc_val_model(i) for i in xrange(n_val_batches)]\n",
    "        val_perf = 1- np.mean(val_losses)                        \n",
    "        print('epoch: %i, training time: %.2f secs, train perf: %.2f %%, val perf: %.2f %%' % (epoch, \n",
    "                                         time.time()-start_time, train_perf * 100., val_perf*100.))\n",
    "\n",
    "    prediction1 = np.zeros((test_iter, test_batch_size))\n",
    "    for j in xrange(test_iter):\n",
    "        prediction1[j] = test_model_all_a(test_set_x[test_batch_size*j:test_batch_size*(j+1) , :])\n",
    "        \n",
    "    prediction2 = test_model_all_b(test_set_x[-extra_test_size: , :])    \n",
    "    prediction = list(prediction1.reshape(test_batch_size * test_iter)) + list(prediction2)\n",
    "    return prediction\n",
    "        \n",
    "def shared_dataset(data_xy, borrow=True):\n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "        The reason we store our dataset in shared variables is to allow\n",
    "        Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "        Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "        is needed (the default behaviour if the data is not in a shared\n",
    "        variable) would lead to a large decrease in performance.\n",
    "        \"\"\"\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "        \n",
    "def sgd_updates_adadelta(params,cost,rho=0.95,epsilon=1e-6,norm_lim=9,word_vec_name='Words'):\n",
    "    \"\"\"\n",
    "    adadelta update rule, mostly from\n",
    "    https://groups.google.com/forum/#!topic/pylearn-dev/3QbKtCumAW4 (for Adadelta)\n",
    "    \"\"\"\n",
    "    updates = OrderedDict({})\n",
    "    exp_sqr_grads = OrderedDict({})\n",
    "    exp_sqr_ups = OrderedDict({})\n",
    "    gparams = []\n",
    "    for param in params:\n",
    "        empty = np.zeros_like(param.get_value())\n",
    "        exp_sqr_grads[param] = theano.shared(value=as_floatX(empty),name=\"exp_grad_%s\" % param.name)\n",
    "        gp = T.grad(cost, param)\n",
    "        exp_sqr_ups[param] = theano.shared(value=as_floatX(empty), name=\"exp_grad_%s\" % param.name)\n",
    "        gparams.append(gp)\n",
    "    for param, gp in zip(params, gparams):\n",
    "        exp_sg = exp_sqr_grads[param]\n",
    "        exp_su = exp_sqr_ups[param]\n",
    "        up_exp_sg = rho * exp_sg + (1 - rho) * T.sqr(gp)\n",
    "        updates[exp_sg] = up_exp_sg\n",
    "        step =  -(T.sqrt(exp_su + epsilon) / T.sqrt(up_exp_sg + epsilon)) * gp\n",
    "        updates[exp_su] = rho * exp_su + (1 - rho) * T.sqr(step)\n",
    "        stepped_param = param + step\n",
    "        if (param.get_value(borrow=True).ndim == 2) and (param.name!='Words'):\n",
    "            col_norms = T.sqrt(T.sum(T.sqr(stepped_param), axis=0))\n",
    "            desired_norms = T.clip(col_norms, 0, T.sqrt(norm_lim))\n",
    "            scale = desired_norms / (1e-7 + col_norms)\n",
    "            updates[param] = stepped_param * scale\n",
    "        else:\n",
    "            updates[param] = stepped_param      \n",
    "    return updates \n",
    "\n",
    "def as_floatX(variable):\n",
    "    if isinstance(variable, float):\n",
    "        return np.cast[theano.config.floatX](variable)\n",
    "\n",
    "    if isinstance(variable, np.ndarray):\n",
    "        return np.cast[theano.config.floatX](variable)\n",
    "    return theano.tensor.cast(variable, theano.config.floatX)\n",
    "    \n",
    "def safe_update(dict_to, dict_from):\n",
    "    \"\"\"\n",
    "    re-make update dictionary for safe updating\n",
    "    \"\"\"\n",
    "    for key, val in dict(dict_from).iteritems():\n",
    "        if key in dict_to:\n",
    "            raise KeyError(key)\n",
    "        dict_to[key] = val\n",
    "    return dict_to\n",
    "    \n",
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in xrange(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l+2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_train_valid_data(train_revs, word_idx_map, cv, max_l = 51, k = 300, filter_h = 5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, valid = [], []\n",
    "    for rev in train_revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h)   \n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]==cv:            \n",
    "            valid.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)\n",
    " \n",
    "    train = np.array(train,dtype=\"int\")\n",
    "    valid = np.array(valid,dtype='int' )\n",
    "    return [train, valid]    \n",
    "\n",
    "def make_idx_data1(revs, word_idx_map, max_l = 51, k = 300, filter_h = 5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) \n",
    "        sent.append(rev[\"y\"])\n",
    "        test.append(sent)  \n",
    "        \n",
    "    test = np.array(test,dtype=\"int\")\n",
    "    return [test]  \n",
    "\n",
    "def make_idx_data2(revs, word_idx_map, max_l = 51, k = 300, filter_h = 5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) \n",
    "        sent.append(rev[\"y\"])\n",
    "        test.append(sent)  \n",
    "        \n",
    "    test = np.array(test,dtype=\"int\")\n",
    "    return test\n",
    "\n",
    "def make_idx_data3(revs, word_idx_map, max_l = 51, k = 300, filter_h = 5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h)   \n",
    "        test.append(sent)  \n",
    "        \n",
    "    test = np.array(test,dtype=\"int\")\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... Data loaded!\n"
     ]
    }
   ],
   "source": [
    "print 'Loading data...',\n",
    "x = cPickle.load(open(\"mr.p35\",\"rb\"))\n",
    "train_revs,valid_revs,test_revs,W1,W2,W3,W4,W5,W6,word_idx_map,vocab = x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10]\n",
    "print \"Data loaded!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = pd.DataFrame.from_csv('all_train1.csv', index_col=False)\n",
    "valid_csv = pd.DataFrame.from_csv('valid.csv'  , index_col=False)\n",
    "test_csv  = pd.DataFrame.from_csv('test.csv'   , index_col=False)\n",
    "datasets  = make_idx_data1(train_revs, word_idx_map, max_l = 53, k = 300, filter_h = 5)\n",
    "valid     = make_idx_data2(valid_revs, word_idx_map, max_l = 53, k = 300, filter_h = 5)\n",
    "test      = make_idx_data3(test_revs , word_idx_map, max_l = 53, k = 300, filter_h = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets.append(valid)\n",
    "datasets.append(test)\n",
    "y_test = np.array(test_csv['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile(\"conv_net_classes.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.38 secs, train perf: 90.31 %, val perf: 83.88 %\n",
      "epoch: 2, training time: 164.35 secs, train perf: 88.80 %, val perf: 81.53 %\n",
      "epoch: 3, training time: 164.35 secs, train perf: 94.92 %, val perf: 84.00 %\n",
      "epoch: 4, training time: 164.89 secs, train perf: 95.82 %, val perf: 85.65 %\n",
      "epoch: 5, training time: 164.64 secs, train perf: 96.38 %, val perf: 85.53 %\n",
      "epoch: 6, training time: 164.65 secs, train perf: 96.84 %, val perf: 85.65 %\n",
      "epoch: 7, training time: 164.48 secs, train perf: 97.22 %, val perf: 84.71 %\n",
      "epoch: 8, training time: 164.47 secs, train perf: 97.44 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 165.67 secs, train perf: 97.64 %, val perf: 85.65 %\n",
      "epoch: 10, training time: 167.95 secs, train perf: 97.89 %, val perf: 86.59 %\n",
      "86.4360241625\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.56 secs, train perf: 90.30 %, val perf: 83.88 %\n",
      "epoch: 2, training time: 164.68 secs, train perf: 90.76 %, val perf: 83.29 %\n",
      "epoch: 3, training time: 164.19 secs, train perf: 94.96 %, val perf: 84.94 %\n",
      "epoch: 4, training time: 163.98 secs, train perf: 95.78 %, val perf: 86.12 %\n",
      "epoch: 5, training time: 164.00 secs, train perf: 96.41 %, val perf: 85.65 %\n",
      "epoch: 6, training time: 163.98 secs, train perf: 96.78 %, val perf: 85.41 %\n",
      "epoch: 7, training time: 164.02 secs, train perf: 97.30 %, val perf: 84.71 %\n",
      "epoch: 8, training time: 164.67 secs, train perf: 97.30 %, val perf: 84.71 %\n",
      "epoch: 9, training time: 167.53 secs, train perf: 97.64 %, val perf: 85.18 %\n",
      "epoch: 10, training time: 167.49 secs, train perf: 97.89 %, val perf: 85.06 %\n",
      "86.1614497529\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 167.77 secs, train perf: 90.24 %, val perf: 83.88 %\n",
      "epoch: 2, training time: 170.03 secs, train perf: 89.71 %, val perf: 82.35 %\n",
      "epoch: 3, training time: 171.33 secs, train perf: 94.93 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 171.23 secs, train perf: 95.82 %, val perf: 85.18 %\n",
      "epoch: 5, training time: 177.14 secs, train perf: 96.24 %, val perf: 86.47 %\n",
      "epoch: 6, training time: 175.52 secs, train perf: 96.85 %, val perf: 86.00 %\n",
      "epoch: 7, training time: 172.87 secs, train perf: 97.29 %, val perf: 85.41 %\n",
      "epoch: 8, training time: 172.65 secs, train perf: 97.49 %, val perf: 85.76 %\n",
      "epoch: 9, training time: 172.88 secs, train perf: 97.69 %, val perf: 85.29 %\n",
      "epoch: 10, training time: 172.88 secs, train perf: 97.85 %, val perf: 85.18 %\n",
      "86.2163646348\n",
      "Test Accuracy  : 86.2712795167 %\n"
     ]
    }
   ],
   "source": [
    "score1 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W1, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score1[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score1[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score1.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 172.90 secs, train perf: 90.54 %, val perf: 84.82 %\n",
      "epoch: 2, training time: 173.09 secs, train perf: 90.76 %, val perf: 82.94 %\n",
      "epoch: 3, training time: 172.91 secs, train perf: 95.32 %, val perf: 85.18 %\n",
      "epoch: 4, training time: 172.85 secs, train perf: 96.06 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 172.96 secs, train perf: 96.54 %, val perf: 84.94 %\n",
      "epoch: 6, training time: 172.87 secs, train perf: 97.05 %, val perf: 86.12 %\n",
      "epoch: 7, training time: 172.86 secs, train perf: 97.43 %, val perf: 84.82 %\n",
      "epoch: 8, training time: 172.73 secs, train perf: 97.63 %, val perf: 85.18 %\n",
      "epoch: 9, training time: 172.86 secs, train perf: 97.84 %, val perf: 84.94 %\n",
      "epoch: 10, training time: 172.78 secs, train perf: 97.93 %, val perf: 85.29 %\n",
      "85.9967051071\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 172.92 secs, train perf: 90.93 %, val perf: 84.59 %\n",
      "epoch: 2, training time: 173.01 secs, train perf: 91.07 %, val perf: 83.88 %\n",
      "epoch: 3, training time: 173.05 secs, train perf: 95.26 %, val perf: 85.06 %\n",
      "epoch: 4, training time: 172.86 secs, train perf: 95.98 %, val perf: 85.53 %\n",
      "epoch: 5, training time: 172.90 secs, train perf: 96.47 %, val perf: 85.29 %\n",
      "epoch: 6, training time: 172.96 secs, train perf: 97.07 %, val perf: 85.76 %\n",
      "epoch: 7, training time: 172.90 secs, train perf: 97.43 %, val perf: 84.47 %\n",
      "epoch: 8, training time: 173.08 secs, train perf: 97.66 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 173.03 secs, train perf: 97.78 %, val perf: 85.41 %\n",
      "epoch: 10, training time: 173.24 secs, train perf: 98.03 %, val perf: 85.53 %\n",
      "85.8319604613\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 175.22 secs, train perf: 90.45 %, val perf: 84.35 %\n",
      "epoch: 2, training time: 174.02 secs, train perf: 90.72 %, val perf: 83.06 %\n",
      "epoch: 3, training time: 175.02 secs, train perf: 95.33 %, val perf: 85.06 %\n",
      "epoch: 4, training time: 168.36 secs, train perf: 96.08 %, val perf: 85.29 %\n",
      "epoch: 5, training time: 164.06 secs, train perf: 96.57 %, val perf: 85.53 %\n",
      "epoch: 6, training time: 164.11 secs, train perf: 97.04 %, val perf: 85.65 %\n",
      "epoch: 7, training time: 164.93 secs, train perf: 97.29 %, val perf: 84.82 %\n",
      "epoch: 8, training time: 164.97 secs, train perf: 97.60 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 164.85 secs, train perf: 97.75 %, val perf: 85.06 %\n",
      "epoch: 10, training time: 164.73 secs, train perf: 97.98 %, val perf: 85.18 %\n",
      "85.8868753432\n",
      "Test Accuracy  : 85.9051803039 %\n"
     ]
    }
   ],
   "source": [
    "score2 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W2, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score2[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score2[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score2.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.83 secs, train perf: 91.07 %, val perf: 84.59 %\n",
      "epoch: 2, training time: 172.54 secs, train perf: 91.38 %, val perf: 83.18 %\n",
      "epoch: 3, training time: 174.73 secs, train perf: 95.43 %, val perf: 85.88 %\n",
      "epoch: 4, training time: 173.95 secs, train perf: 96.11 %, val perf: 85.29 %\n",
      "epoch: 5, training time: 170.04 secs, train perf: 96.60 %, val perf: 85.29 %\n",
      "epoch: 6, training time: 164.21 secs, train perf: 96.96 %, val perf: 85.65 %\n",
      "epoch: 7, training time: 164.24 secs, train perf: 97.49 %, val perf: 83.76 %\n",
      "epoch: 8, training time: 164.18 secs, train perf: 97.66 %, val perf: 85.18 %\n",
      "epoch: 9, training time: 164.13 secs, train perf: 97.77 %, val perf: 84.94 %\n",
      "epoch: 10, training time: 164.18 secs, train perf: 98.05 %, val perf: 85.18 %\n",
      "86.875343218\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.24 secs, train perf: 90.93 %, val perf: 83.65 %\n",
      "epoch: 2, training time: 167.19 secs, train perf: 91.19 %, val perf: 82.12 %\n",
      "epoch: 3, training time: 167.78 secs, train perf: 95.14 %, val perf: 85.06 %\n",
      "epoch: 4, training time: 172.59 secs, train perf: 96.07 %, val perf: 85.76 %\n",
      "epoch: 5, training time: 173.89 secs, train perf: 96.68 %, val perf: 85.06 %\n",
      "epoch: 6, training time: 174.19 secs, train perf: 97.04 %, val perf: 86.12 %\n",
      "epoch: 7, training time: 173.72 secs, train perf: 97.50 %, val perf: 85.06 %\n",
      "epoch: 8, training time: 173.93 secs, train perf: 97.73 %, val perf: 85.41 %\n",
      "epoch: 9, training time: 173.66 secs, train perf: 97.79 %, val perf: 85.18 %\n",
      "epoch: 10, training time: 172.58 secs, train perf: 98.07 %, val perf: 85.29 %\n",
      "86.4909390445\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 165.30 secs, train perf: 91.04 %, val perf: 83.65 %\n",
      "epoch: 2, training time: 164.36 secs, train perf: 91.67 %, val perf: 83.65 %\n",
      "epoch: 3, training time: 164.93 secs, train perf: 95.21 %, val perf: 85.41 %\n",
      "epoch: 4, training time: 164.81 secs, train perf: 96.12 %, val perf: 85.53 %\n",
      "epoch: 5, training time: 164.61 secs, train perf: 96.64 %, val perf: 85.65 %\n",
      "epoch: 6, training time: 164.78 secs, train perf: 96.94 %, val perf: 86.47 %\n",
      "epoch: 7, training time: 164.76 secs, train perf: 97.54 %, val perf: 84.94 %\n",
      "epoch: 8, training time: 165.19 secs, train perf: 97.68 %, val perf: 86.24 %\n",
      "epoch: 9, training time: 164.66 secs, train perf: 97.84 %, val perf: 86.24 %\n",
      "epoch: 10, training time: 164.78 secs, train perf: 98.04 %, val perf: 86.12 %\n",
      "86.2163646348\n",
      "Test Accuracy  : 86.5275489658 %\n"
     ]
    }
   ],
   "source": [
    "score3 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W3, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score3[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score3[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score3.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 166.12 secs, train perf: 91.35 %, val perf: 84.00 %\n",
      "epoch: 2, training time: 168.17 secs, train perf: 93.01 %, val perf: 84.47 %\n",
      "epoch: 3, training time: 168.22 secs, train perf: 94.74 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 168.14 secs, train perf: 96.18 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 168.13 secs, train perf: 96.71 %, val perf: 85.76 %\n",
      "epoch: 6, training time: 168.80 secs, train perf: 97.08 %, val perf: 85.65 %\n",
      "epoch: 7, training time: 168.89 secs, train perf: 97.52 %, val perf: 84.71 %\n",
      "epoch: 8, training time: 168.49 secs, train perf: 97.78 %, val perf: 85.65 %\n",
      "epoch: 9, training time: 167.72 secs, train perf: 97.88 %, val perf: 84.94 %\n",
      "epoch: 10, training time: 167.65 secs, train perf: 98.06 %, val perf: 85.29 %\n",
      "86.1614497529\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.26 secs, train perf: 91.31 %, val perf: 84.59 %\n",
      "epoch: 2, training time: 164.22 secs, train perf: 92.61 %, val perf: 83.88 %\n",
      "epoch: 3, training time: 164.23 secs, train perf: 95.08 %, val perf: 85.53 %\n",
      "epoch: 4, training time: 164.27 secs, train perf: 96.22 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 164.18 secs, train perf: 96.74 %, val perf: 85.53 %\n",
      "epoch: 6, training time: 164.26 secs, train perf: 96.96 %, val perf: 85.29 %\n",
      "epoch: 7, training time: 165.70 secs, train perf: 97.46 %, val perf: 84.35 %\n",
      "epoch: 8, training time: 167.66 secs, train perf: 97.78 %, val perf: 85.18 %\n",
      "epoch: 9, training time: 167.62 secs, train perf: 97.80 %, val perf: 85.65 %\n",
      "epoch: 10, training time: 168.63 secs, train perf: 98.08 %, val perf: 85.76 %\n",
      "86.4909390445\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.44 secs, train perf: 91.29 %, val perf: 84.47 %\n",
      "epoch: 2, training time: 164.17 secs, train perf: 92.42 %, val perf: 84.12 %\n",
      "epoch: 3, training time: 164.08 secs, train perf: 95.17 %, val perf: 85.53 %\n",
      "epoch: 4, training time: 164.16 secs, train perf: 96.16 %, val perf: 85.65 %\n",
      "epoch: 5, training time: 164.22 secs, train perf: 96.74 %, val perf: 85.53 %\n",
      "epoch: 6, training time: 164.07 secs, train perf: 97.04 %, val perf: 85.41 %\n",
      "epoch: 7, training time: 164.13 secs, train perf: 97.48 %, val perf: 84.35 %\n",
      "epoch: 8, training time: 164.14 secs, train perf: 97.74 %, val perf: 85.65 %\n",
      "epoch: 9, training time: 164.39 secs, train perf: 97.87 %, val perf: 85.29 %\n",
      "epoch: 10, training time: 165.70 secs, train perf: 98.09 %, val perf: 85.53 %\n",
      "86.8204283361\n",
      "Test Accuracy  : 86.4909390445 %\n"
     ]
    }
   ],
   "source": [
    "score4 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W4, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score4[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score4[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score4.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.326194398682048, 86.71, 86.82]\n",
      "86.6187314662\n"
     ]
    }
   ],
   "source": [
    "score5 = [0,86.71,86.82]\n",
    "for i in xrange(1):\n",
    "    y_prediction = train_conv_net(datasets, W5, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score5[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score5[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score5.mean()) + ' %'\n",
    "print score5\n",
    "print np.array(score5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 164.95 secs, train perf: 91.34 %, val perf: 84.82 %\n",
      "epoch: 2, training time: 164.85 secs, train perf: 92.63 %, val perf: 84.12 %\n",
      "epoch: 3, training time: 164.80 secs, train perf: 95.02 %, val perf: 84.82 %\n",
      "epoch: 4, training time: 164.87 secs, train perf: 96.10 %, val perf: 85.88 %\n",
      "epoch: 5, training time: 173.25 secs, train perf: 96.82 %, val perf: 85.06 %\n",
      "epoch: 6, training time: 178.13 secs, train perf: 97.05 %, val perf: 86.59 %\n",
      "epoch: 7, training time: 177.55 secs, train perf: 97.54 %, val perf: 84.94 %\n",
      "epoch: 8, training time: 177.89 secs, train perf: 97.79 %, val perf: 85.53 %\n",
      "epoch: 9, training time: 178.09 secs, train perf: 97.83 %, val perf: 85.53 %\n",
      "epoch: 10, training time: 180.84 secs, train perf: 98.13 %, val perf: 86.24 %\n",
      "86.2712795167\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 179.26 secs, train perf: 91.23 %, val perf: 84.94 %\n",
      "epoch: 2, training time: 185.11 secs, train perf: 92.54 %, val perf: 84.12 %\n",
      "epoch: 3, training time: 185.30 secs, train perf: 95.03 %, val perf: 84.71 %\n",
      "epoch: 4, training time: 185.30 secs, train perf: 96.17 %, val perf: 86.12 %\n",
      "epoch: 5, training time: 186.26 secs, train perf: 96.76 %, val perf: 86.12 %\n",
      "epoch: 6, training time: 186.62 secs, train perf: 97.19 %, val perf: 86.24 %\n",
      "epoch: 7, training time: 183.09 secs, train perf: 97.56 %, val perf: 84.24 %\n",
      "epoch: 8, training time: 178.49 secs, train perf: 97.75 %, val perf: 85.76 %\n",
      "epoch: 9, training time: 173.69 secs, train perf: 97.83 %, val perf: 85.65 %\n",
      "epoch: 10, training time: 173.86 secs, train perf: 98.09 %, val perf: 85.41 %\n",
      "86.2712795167\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 174.05 secs, train perf: 91.42 %, val perf: 84.59 %\n",
      "epoch: 2, training time: 174.10 secs, train perf: 92.82 %, val perf: 84.12 %\n",
      "epoch: 3, training time: 174.25 secs, train perf: 95.13 %, val perf: 84.94 %\n",
      "epoch: 4, training time: 173.89 secs, train perf: 96.07 %, val perf: 86.47 %\n",
      "epoch: 5, training time: 174.63 secs, train perf: 96.79 %, val perf: 85.53 %\n",
      "epoch: 6, training time: 176.49 secs, train perf: 97.12 %, val perf: 86.59 %\n",
      "epoch: 7, training time: 173.78 secs, train perf: 97.50 %, val perf: 84.35 %\n",
      "epoch: 8, training time: 175.62 secs, train perf: 97.77 %, val perf: 85.18 %\n",
      "epoch: 9, training time: 174.95 secs, train perf: 97.86 %, val perf: 85.76 %\n",
      "epoch: 10, training time: 175.31 secs, train perf: 98.04 %, val perf: 86.47 %\n",
      "86.3811092806\n",
      "Test Accuracy  : 86.307889438 %\n"
     ]
    }
   ],
   "source": [
    "score6 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W6, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=True, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score6[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score6[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score6.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.29 secs, train perf: 87.23 %, val perf: 83.41 %\n",
      "epoch: 2, training time: 90.53 secs, train perf: 85.51 %, val perf: 82.24 %\n",
      "epoch: 3, training time: 90.49 secs, train perf: 91.09 %, val perf: 84.59 %\n",
      "epoch: 4, training time: 90.36 secs, train perf: 92.31 %, val perf: 84.59 %\n",
      "epoch: 5, training time: 90.65 secs, train perf: 93.69 %, val perf: 84.71 %\n",
      "epoch: 6, training time: 90.48 secs, train perf: 94.43 %, val perf: 84.35 %\n",
      "epoch: 7, training time: 90.21 secs, train perf: 94.22 %, val perf: 82.94 %\n",
      "epoch: 8, training time: 90.19 secs, train perf: 95.21 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 90.18 secs, train perf: 95.57 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 90.24 secs, train perf: 95.85 %, val perf: 84.94 %\n",
      "86.3811092806\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.30 secs, train perf: 87.23 %, val perf: 83.41 %\n",
      "epoch: 2, training time: 90.26 secs, train perf: 85.51 %, val perf: 82.24 %\n",
      "epoch: 3, training time: 90.27 secs, train perf: 91.09 %, val perf: 84.59 %\n",
      "epoch: 4, training time: 90.38 secs, train perf: 92.31 %, val perf: 84.59 %\n",
      "epoch: 5, training time: 108.81 secs, train perf: 93.69 %, val perf: 84.71 %\n",
      "epoch: 6, training time: 90.48 secs, train perf: 94.43 %, val perf: 84.35 %\n",
      "epoch: 7, training time: 90.96 secs, train perf: 94.22 %, val perf: 82.94 %\n",
      "epoch: 8, training time: 91.02 secs, train perf: 95.21 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 90.73 secs, train perf: 95.57 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 90.88 secs, train perf: 95.85 %, val perf: 84.94 %\n",
      "86.3811092806\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.91 secs, train perf: 87.23 %, val perf: 83.41 %\n",
      "epoch: 2, training time: 90.76 secs, train perf: 85.51 %, val perf: 82.24 %\n",
      "epoch: 3, training time: 90.71 secs, train perf: 91.09 %, val perf: 84.59 %\n",
      "epoch: 4, training time: 90.78 secs, train perf: 92.31 %, val perf: 84.59 %\n",
      "epoch: 5, training time: 90.92 secs, train perf: 93.69 %, val perf: 84.71 %\n",
      "epoch: 6, training time: 90.91 secs, train perf: 94.43 %, val perf: 84.35 %\n",
      "epoch: 7, training time: 90.73 secs, train perf: 94.22 %, val perf: 82.94 %\n",
      "epoch: 8, training time: 90.26 secs, train perf: 95.21 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 150.96 secs, train perf: 95.57 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 131.63 secs, train perf: 95.85 %, val perf: 84.94 %\n",
      "86.3811092806\n",
      "Test Accuracy  : 86.3811092806 %\n"
     ]
    }
   ],
   "source": [
    "score1 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W1, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score1[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score1[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score1.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 105.94 secs, train perf: 87.82 %, val perf: 84.00 %\n",
      "epoch: 2, training time: 90.83 secs, train perf: 86.03 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 91.22 secs, train perf: 92.32 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 90.74 secs, train perf: 93.39 %, val perf: 83.41 %\n",
      "epoch: 5, training time: 90.73 secs, train perf: 94.21 %, val perf: 84.35 %\n",
      "epoch: 6, training time: 90.42 secs, train perf: 94.89 %, val perf: 84.47 %\n",
      "epoch: 7, training time: 90.42 secs, train perf: 95.37 %, val perf: 83.88 %\n",
      "epoch: 8, training time: 90.91 secs, train perf: 95.77 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 91.22 secs, train perf: 95.77 %, val perf: 84.24 %\n",
      "epoch: 10, training time: 91.28 secs, train perf: 96.17 %, val perf: 83.65 %\n",
      "87.0400878638\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 98.96 secs, train perf: 87.82 %, val perf: 84.00 %\n",
      "epoch: 2, training time: 100.80 secs, train perf: 86.03 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 99.95 secs, train perf: 92.32 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 99.07 secs, train perf: 93.39 %, val perf: 83.41 %\n",
      "epoch: 5, training time: 101.18 secs, train perf: 94.21 %, val perf: 84.35 %\n",
      "epoch: 6, training time: 98.65 secs, train perf: 94.89 %, val perf: 84.47 %\n",
      "epoch: 7, training time: 90.62 secs, train perf: 95.37 %, val perf: 83.88 %\n",
      "epoch: 8, training time: 90.36 secs, train perf: 95.77 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 90.31 secs, train perf: 95.77 %, val perf: 84.24 %\n",
      "epoch: 10, training time: 90.45 secs, train perf: 96.17 %, val perf: 83.65 %\n",
      "87.0400878638\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.49 secs, train perf: 87.82 %, val perf: 84.00 %\n",
      "epoch: 2, training time: 90.95 secs, train perf: 86.03 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 94.77 secs, train perf: 92.32 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 100.07 secs, train perf: 93.39 %, val perf: 83.41 %\n",
      "epoch: 5, training time: 99.80 secs, train perf: 94.21 %, val perf: 84.35 %\n",
      "epoch: 6, training time: 99.93 secs, train perf: 94.89 %, val perf: 84.47 %\n",
      "epoch: 7, training time: 100.17 secs, train perf: 95.37 %, val perf: 83.88 %\n",
      "epoch: 8, training time: 99.79 secs, train perf: 95.77 %, val perf: 84.00 %\n",
      "epoch: 9, training time: 99.88 secs, train perf: 95.77 %, val perf: 84.24 %\n",
      "epoch: 10, training time: 99.81 secs, train perf: 96.17 %, val perf: 83.65 %\n",
      "87.0400878638\n",
      "Test Accuracy  : 87.0400878638 %\n"
     ]
    }
   ],
   "source": [
    "score2 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W2, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score2[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score2[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score2.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.17 secs, train perf: 88.41 %, val perf: 84.24 %\n",
      "epoch: 2, training time: 91.15 secs, train perf: 86.87 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 91.13 secs, train perf: 92.46 %, val perf: 83.65 %\n",
      "epoch: 4, training time: 91.16 secs, train perf: 93.81 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 91.21 secs, train perf: 94.79 %, val perf: 85.18 %\n",
      "epoch: 6, training time: 91.24 secs, train perf: 95.22 %, val perf: 83.88 %\n",
      "epoch: 7, training time: 91.25 secs, train perf: 95.33 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 91.71 secs, train perf: 95.90 %, val perf: 84.35 %\n",
      "epoch: 9, training time: 99.86 secs, train perf: 96.20 %, val perf: 85.41 %\n",
      "epoch: 10, training time: 100.02 secs, train perf: 96.57 %, val perf: 84.94 %\n",
      "86.4360241625\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 99.68 secs, train perf: 88.41 %, val perf: 84.24 %\n",
      "epoch: 2, training time: 99.40 secs, train perf: 86.87 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 90.64 secs, train perf: 92.46 %, val perf: 83.65 %\n",
      "epoch: 4, training time: 90.59 secs, train perf: 93.81 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 90.85 secs, train perf: 94.79 %, val perf: 85.18 %\n",
      "epoch: 6, training time: 90.78 secs, train perf: 95.22 %, val perf: 83.88 %\n",
      "epoch: 7, training time: 90.73 secs, train perf: 95.33 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 90.87 secs, train perf: 95.90 %, val perf: 84.35 %\n",
      "epoch: 9, training time: 90.83 secs, train perf: 96.20 %, val perf: 85.41 %\n",
      "epoch: 10, training time: 91.22 secs, train perf: 96.57 %, val perf: 84.94 %\n",
      "86.4360241625\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.46 secs, train perf: 88.41 %, val perf: 84.24 %\n",
      "epoch: 2, training time: 91.46 secs, train perf: 86.87 %, val perf: 81.06 %\n",
      "epoch: 3, training time: 90.77 secs, train perf: 92.46 %, val perf: 83.65 %\n",
      "epoch: 4, training time: 90.59 secs, train perf: 93.81 %, val perf: 85.41 %\n",
      "epoch: 5, training time: 90.79 secs, train perf: 94.79 %, val perf: 85.18 %\n",
      "epoch: 6, training time: 91.39 secs, train perf: 95.22 %, val perf: 83.88 %\n",
      "epoch: 7, training time: 91.40 secs, train perf: 95.33 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 91.39 secs, train perf: 95.90 %, val perf: 84.35 %\n",
      "epoch: 9, training time: 91.39 secs, train perf: 96.20 %, val perf: 85.41 %\n",
      "epoch: 10, training time: 91.36 secs, train perf: 96.57 %, val perf: 84.94 %\n",
      "86.4360241625\n",
      "Test Accuracy  : 86.4360241625 %\n"
     ]
    }
   ],
   "source": [
    "score3 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W3, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score3[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score3[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score3.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.21 secs, train perf: 88.42 %, val perf: 83.53 %\n",
      "epoch: 2, training time: 91.09 secs, train perf: 89.98 %, val perf: 83.53 %\n",
      "epoch: 3, training time: 91.14 secs, train perf: 92.61 %, val perf: 84.47 %\n",
      "epoch: 4, training time: 93.12 secs, train perf: 94.04 %, val perf: 84.94 %\n",
      "epoch: 5, training time: 98.87 secs, train perf: 94.69 %, val perf: 84.24 %\n",
      "epoch: 6, training time: 98.49 secs, train perf: 95.33 %, val perf: 84.24 %\n",
      "epoch: 7, training time: 92.76 secs, train perf: 95.75 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 90.50 secs, train perf: 96.33 %, val perf: 83.76 %\n",
      "epoch: 9, training time: 90.50 secs, train perf: 96.45 %, val perf: 83.88 %\n",
      "epoch: 10, training time: 91.03 secs, train perf: 96.71 %, val perf: 84.47 %\n",
      "86.6556836903\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.23 secs, train perf: 88.42 %, val perf: 83.53 %\n",
      "epoch: 2, training time: 91.01 secs, train perf: 89.98 %, val perf: 83.53 %\n",
      "epoch: 3, training time: 91.32 secs, train perf: 92.61 %, val perf: 84.47 %\n",
      "epoch: 4, training time: 91.28 secs, train perf: 94.04 %, val perf: 84.94 %\n",
      "epoch: 5, training time: 91.32 secs, train perf: 94.69 %, val perf: 84.24 %\n",
      "epoch: 6, training time: 91.25 secs, train perf: 95.33 %, val perf: 84.24 %\n",
      "epoch: 7, training time: 91.20 secs, train perf: 95.75 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 91.15 secs, train perf: 96.33 %, val perf: 83.76 %\n",
      "epoch: 9, training time: 90.82 secs, train perf: 96.45 %, val perf: 83.88 %\n",
      "epoch: 10, training time: 91.06 secs, train perf: 96.71 %, val perf: 84.47 %\n",
      "86.6556836903\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.20 secs, train perf: 88.42 %, val perf: 83.53 %\n",
      "epoch: 2, training time: 91.16 secs, train perf: 89.98 %, val perf: 83.53 %\n",
      "epoch: 3, training time: 91.19 secs, train perf: 92.61 %, val perf: 84.47 %\n",
      "epoch: 4, training time: 90.85 secs, train perf: 94.04 %, val perf: 84.94 %\n",
      "epoch: 5, training time: 90.47 secs, train perf: 94.69 %, val perf: 84.24 %\n",
      "epoch: 6, training time: 90.49 secs, train perf: 95.33 %, val perf: 84.24 %\n",
      "epoch: 7, training time: 90.49 secs, train perf: 95.75 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 90.50 secs, train perf: 96.33 %, val perf: 83.76 %\n",
      "epoch: 9, training time: 90.49 secs, train perf: 96.45 %, val perf: 83.88 %\n",
      "epoch: 10, training time: 90.54 secs, train perf: 96.71 %, val perf: 84.47 %\n",
      "86.6556836903\n",
      "Test Accuracy  : 86.6556836903 %\n"
     ]
    }
   ],
   "source": [
    "score4 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W4, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score4[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score4[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score4.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.34 secs, train perf: 88.58 %, val perf: 83.76 %\n",
      "epoch: 2, training time: 90.51 secs, train perf: 89.16 %, val perf: 83.18 %\n",
      "epoch: 3, training time: 90.50 secs, train perf: 90.60 %, val perf: 82.82 %\n",
      "epoch: 4, training time: 90.48 secs, train perf: 93.71 %, val perf: 84.00 %\n",
      "epoch: 5, training time: 90.47 secs, train perf: 94.76 %, val perf: 84.12 %\n",
      "epoch: 6, training time: 90.50 secs, train perf: 95.48 %, val perf: 82.94 %\n",
      "epoch: 7, training time: 90.88 secs, train perf: 95.34 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 90.98 secs, train perf: 96.29 %, val perf: 84.12 %\n",
      "epoch: 9, training time: 90.88 secs, train perf: 96.52 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 90.96 secs, train perf: 96.78 %, val perf: 84.12 %\n",
      "86.2163646348\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.04 secs, train perf: 88.58 %, val perf: 83.76 %\n",
      "epoch: 2, training time: 90.97 secs, train perf: 89.16 %, val perf: 83.18 %\n",
      "epoch: 3, training time: 90.78 secs, train perf: 90.60 %, val perf: 82.82 %\n",
      "epoch: 4, training time: 90.99 secs, train perf: 93.71 %, val perf: 84.00 %\n",
      "epoch: 5, training time: 90.94 secs, train perf: 94.76 %, val perf: 84.12 %\n",
      "epoch: 6, training time: 92.33 secs, train perf: 95.48 %, val perf: 82.94 %\n",
      "epoch: 7, training time: 92.83 secs, train perf: 95.34 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 92.82 secs, train perf: 96.29 %, val perf: 84.12 %\n",
      "epoch: 9, training time: 99.49 secs, train perf: 96.52 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 99.52 secs, train perf: 96.78 %, val perf: 84.12 %\n",
      "86.2163646348\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 99.28 secs, train perf: 88.58 %, val perf: 83.76 %\n",
      "epoch: 2, training time: 99.31 secs, train perf: 89.16 %, val perf: 83.18 %\n",
      "epoch: 3, training time: 99.78 secs, train perf: 90.60 %, val perf: 82.82 %\n",
      "epoch: 4, training time: 100.23 secs, train perf: 93.71 %, val perf: 84.00 %\n",
      "epoch: 5, training time: 98.88 secs, train perf: 94.76 %, val perf: 84.12 %\n",
      "epoch: 6, training time: 98.97 secs, train perf: 95.48 %, val perf: 82.94 %\n",
      "epoch: 7, training time: 99.22 secs, train perf: 95.34 %, val perf: 83.65 %\n",
      "epoch: 8, training time: 98.93 secs, train perf: 96.29 %, val perf: 84.12 %\n",
      "epoch: 9, training time: 98.78 secs, train perf: 96.52 %, val perf: 84.12 %\n",
      "epoch: 10, training time: 93.95 secs, train perf: 96.78 %, val perf: 84.12 %\n",
      "86.2163646348\n",
      "Test Accuracy  : 86.2163646348 %\n"
     ]
    }
   ],
   "source": [
    "score5 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W5, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score5[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score5[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score5.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.01 secs, train perf: 88.81 %, val perf: 84.47 %\n",
      "epoch: 2, training time: 90.92 secs, train perf: 88.11 %, val perf: 82.47 %\n",
      "epoch: 3, training time: 90.93 secs, train perf: 92.00 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 90.88 secs, train perf: 93.95 %, val perf: 85.18 %\n",
      "epoch: 5, training time: 97.28 secs, train perf: 94.81 %, val perf: 85.76 %\n",
      "epoch: 6, training time: 99.61 secs, train perf: 95.42 %, val perf: 85.18 %\n",
      "epoch: 7, training time: 99.51 secs, train perf: 95.43 %, val perf: 84.00 %\n",
      "epoch: 8, training time: 99.14 secs, train perf: 96.32 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 99.11 secs, train perf: 96.65 %, val perf: 85.06 %\n",
      "epoch: 10, training time: 99.02 secs, train perf: 96.83 %, val perf: 85.65 %\n",
      "86.4909390445\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 90.96 secs, train perf: 88.81 %, val perf: 84.47 %\n",
      "epoch: 2, training time: 90.91 secs, train perf: 88.11 %, val perf: 82.47 %\n",
      "epoch: 3, training time: 90.93 secs, train perf: 92.00 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 91.63 secs, train perf: 93.95 %, val perf: 85.18 %\n",
      "epoch: 5, training time: 98.87 secs, train perf: 94.81 %, val perf: 85.76 %\n",
      "epoch: 6, training time: 102.44 secs, train perf: 95.42 %, val perf: 85.18 %\n",
      "epoch: 7, training time: 101.70 secs, train perf: 95.43 %, val perf: 84.00 %\n",
      "epoch: 8, training time: 98.07 secs, train perf: 96.32 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 91.12 secs, train perf: 96.65 %, val perf: 85.06 %\n",
      "epoch: 10, training time: 91.31 secs, train perf: 96.83 %, val perf: 85.65 %\n",
      "86.4909390445\n",
      "[('image shape', 61, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', False), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', False), ('sqr_norm_lim', 3), ('shuffle_batch', True)]\n",
      "... training\n",
      "epoch: 1, training time: 91.35 secs, train perf: 88.81 %, val perf: 84.47 %\n",
      "epoch: 2, training time: 91.44 secs, train perf: 88.11 %, val perf: 82.47 %\n",
      "epoch: 3, training time: 91.54 secs, train perf: 92.00 %, val perf: 84.35 %\n",
      "epoch: 4, training time: 91.02 secs, train perf: 93.95 %, val perf: 85.18 %\n",
      "epoch: 5, training time: 95.48 secs, train perf: 94.81 %, val perf: 85.76 %\n",
      "epoch: 6, training time: 102.19 secs, train perf: 95.42 %, val perf: 85.18 %\n",
      "epoch: 7, training time: 101.34 secs, train perf: 95.43 %, val perf: 84.00 %\n",
      "epoch: 8, training time: 99.98 secs, train perf: 96.32 %, val perf: 84.59 %\n",
      "epoch: 9, training time: 91.24 secs, train perf: 96.65 %, val perf: 85.06 %\n",
      "epoch: 10, training time: 91.13 secs, train perf: 96.83 %, val perf: 85.65 %\n",
      "86.4909390445\n",
      "Test Accuracy  : 86.4909390445 %\n"
     ]
    }
   ],
   "source": [
    "score6 = np.zeros(3)\n",
    "for i in xrange(3):\n",
    "    y_prediction = train_conv_net(datasets, W6, lr_decay=0.95, filter_hs=[3,4,5], conv_non_linear=\"relu\", hidden_units=[100,2], \n",
    "                                  shuffle_batch=True, n_epochs=10, sqr_norm_lim=3, non_static=False, batch_size=50,\n",
    "                                  dropout_rate=[0.5])\n",
    "    \n",
    "    score6[i] = np.sum(y_test == y_prediction, axis = 0) * 100/float(len(y_test))\n",
    "    print score6[i]\n",
    "print 'Test Accuracy ' + ' : ' + str(score6.mean()) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
